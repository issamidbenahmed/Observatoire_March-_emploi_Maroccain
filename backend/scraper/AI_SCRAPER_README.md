# ğŸ¤– Deep AI Scraper - Guide d'utilisation

## ğŸ“‹ PrÃ©requis

### 1. Installer Ollama
```bash
# TÃ©lÃ©charger depuis https://ollama.ai
# Ou si dÃ©jÃ  installÃ©, vÃ©rifier:
ollama --version
```

### 2. TÃ©lÃ©charger un modÃ¨le
```bash
# RecommandÃ© pour l'extraction (rapide et prÃ©cis):
ollama pull llama3.2:latest

# Alternatives:
ollama pull mistral
ollama pull codellama
```

### 3. Lancer Ollama
```bash
ollama serve
```

### 4. Installer les dÃ©pendances Python
```bash
cd backend/scraper
pip install -r requirements_ai.txt
playwright install chromium
```

## ğŸš€ Utilisation

### Ã‰tape 1: Lancer le scraping AI
```bash
cd backend/scraper
python ai_deep_scraper.py
```

**Ce que fait le script:**
- âœ… Scrape Rekrute.com page par page
- âœ… Extrait chaque offre avec Ollama (AI)
- âœ… Parse intelligemment: dates, villes, technologies, compÃ©tences
- âœ… Sauvegarde en JSON au fur et Ã  mesure
- âœ… GÃ¨re les erreurs et continue

**DurÃ©e estimÃ©e:** 2-3 heures pour 1000 offres (avec Ollama local)

### Ã‰tape 2: Importer dans la BD
```bash
cd backend/scraper
python import_ai_data.py ai_scraped_jobs_YYYYMMDD_HHMMSS.json
```

## ğŸ¯ Avantages du Scraper AI

### vs Scraper classique:
| CritÃ¨re | Classique | AI |
|---------|-----------|-----|
| **Dates** | Parsing regex fragile | âœ… ComprÃ©hension contextuelle |
| **Villes** | SÃ©lecteurs CSS | âœ… Extraction intelligente |
| **Technologies** | Liste prÃ©dÃ©finie | âœ… DÃ©tection automatique |
| **CompÃ©tences** | Regex basique | âœ… Extraction sÃ©mantique |
| **Robustesse** | Casse si HTML change | âœ… S'adapte au contenu |

### DonnÃ©es extraites:
```json
{
  "title": "DÃ©veloppeur Full Stack",
  "company": "TechCorp Maroc",
  "location": "Casablanca",
  "date_posted": "2024-12-20",
  "technologies": ["React", "Node.js", "MongoDB", "Docker"],
  "skills": ["Travail d'Ã©quipe", "Agile", "Problem solving"],
  "contract_type": "CDI",
  "experience_required": "3 ans",
  "salary": "15000-20000 MAD",
  "description_summary": "Poste de dÃ©veloppeur full stack..."
}
```

## âš™ï¸ Configuration

### Modifier le modÃ¨le Ollama
Dans `ai_deep_scraper.py`:
```python
OLLAMA_MODEL = "llama3.2:latest"  # Changer ici
```

### Ajuster le nombre de pages
```python
for page_num in range(1, 51):  # Modifier 51 pour plus/moins de pages
```

### Limiter les offres par page (pour test)
```python
for idx, job_url in enumerate(job_links[:10], 1):  # Modifier 10
```

## ğŸ› DÃ©pannage

### Ollama ne rÃ©pond pas
```bash
# VÃ©rifier qu'Ollama tourne:
curl http://localhost:11434/api/tags

# Relancer si nÃ©cessaire:
ollama serve
```

### Extraction JSON Ã©choue
- Le modÃ¨le peut parfois ne pas retourner du JSON valide
- Le script rÃ©essaie automatiquement
- VÃ©rifier les logs pour voir les rÃ©ponses

### Trop lent
- Utiliser un modÃ¨le plus petit: `ollama pull llama3.2:1b`
- RÃ©duire le nombre d'offres par page
- Augmenter le timeout

## ğŸ“Š Monitoring

Le script affiche en temps rÃ©el:
```
ğŸ“„ Page 5/50...
  TrouvÃ© 20 offres
    [1/20] Extraction AI...
      âœ… DÃ©veloppeur Full Stack - React/Node.js
    [2/20] Extraction AI...
      âœ… Data Scientist - Python/TensorFlow
```

Sauvegardes automatiques toutes les 5 pages !

## ğŸ¯ Prochaines Ã©tapes

1. **Tester** avec 1-2 pages d'abord
2. **VÃ©rifier** la qualitÃ© des donnÃ©es dans le JSON
3. **Lancer** le scraping complet
4. **Importer** dans la BD
5. **VÃ©rifier** le dashboard avec les nouvelles donnÃ©es

## ğŸ’¡ Tips

- Lancer le scraping la nuit (long)
- Garder Ollama ouvert pendant tout le processus
- Les fichiers JSON sont sauvegardÃ©s mÃªme en cas d'erreur
- Vous pouvez relancer l'import plusieurs fois (dÃ©tecte les doublons)
